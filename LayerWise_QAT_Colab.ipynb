{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LayerWise-QAT: Sensitivity-Ordered Quantization\n",
    "\n",
    "This notebook implements LayerWise-QAT, an extension of EfficientQAT with sensitivity-based layer ordering.\n",
    "\n",
    "## Key Features:\n",
    "- Sensitivity-ordered block training\n",
    "- Adaptive learning rate scaling\n",
    "- Multiple sensitivity metrics (Fisher, Gradient, Hessian)\n",
    "- Memory-optimized for A100-40GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU and setup environment\n",
    "import torch\n",
    "print(f'CUDA Available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB')\n",
    "else:\n",
    "    print('No GPU available - this will not work!')\n",
    "\n",
    "# Install required packages\n",
    "!pip install -q transformers accelerate datasets lm_eval triton sentencepiece protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (if needed)\n",
    "import os\n",
    "if not os.path.exists('/content/EfficientQAT'):\n",
    "    !git clone https://github.com/OpenGVLab/EfficientQAT.git\n",
    "    %cd EfficientQAT\n",
    "else:\n",
    "    %cd /content/EfficientQAT\n",
    "\n",
    "# Install remaining requirements\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Test Original EfficientQAT Baseline\n",
    "\n",
    "First, let's validate that the original EfficientQAT works in this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick baseline test with small dataset\n",
    "!python main_block_ap.py \\\n",
    "    --model meta-llama/Llama-2-7b-hf \\\n",
    "    --wbits 3 \\\n",
    "    --group_size 128 \\\n",
    "    --calib_dataset redpajama \\\n",
    "    --train_size 64 \\\n",
    "    --val_size 16 \\\n",
    "    --epochs 1 \\\n",
    "    --output_dir ./test_baseline \\\n",
    "    --max_memory \"35GiB\" \\\n",
    "    --eval_ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Test LayerWise-QAT with Sensitivity Ordering\n",
    "\n",
    "Now let's test our new sensitivity-ordered training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test LayerWise-QAT with gradient sensitivity (fastest)\n",
    "!python main_block_ap.py \\\n",
    "    --model meta-llama/Llama-2-7b-hf \\\n",
    "    --wbits 3 \\\n",
    "    --group_size 128 \\\n",
    "    --calib_dataset redpajama \\\n",
    "    --train_size 64 \\\n",
    "    --val_size 16 \\\n",
    "    --epochs 1 \\\n",
    "    --layer_ordering sensitivity \\\n",
    "    --sensitivity_metric gradient \\\n",
    "    --sensitivity_samples 16 \\\n",
    "    --output_dir ./test_layerwise_gradient \\\n",
    "    --max_memory \"35GiB\" \\\n",
    "    --eval_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test LayerWise-QAT with Fisher sensitivity\n",
    "!python main_block_ap.py \\\n",
    "    --model meta-llama/Llama-2-7b-hf \\\n",
    "    --wbits 3 \\\n",
    "    --group_size 128 \\\n",
    "    --calib_dataset redpajama \\\n",
    "    --train_size 64 \\\n",
    "    --val_size 16 \\\n",
    "    --epochs 1 \\\n",
    "    --layer_ordering sensitivity \\\n",
    "    --sensitivity_metric fisher \\\n",
    "    --sensitivity_samples 16 \\\n",
    "    --output_dir ./test_layerwise_fisher \\\n",
    "    --max_memory \"35GiB\" \\\n",
    "    --eval_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with adaptive learning rate scaling\n",
    "!python main_block_ap.py \\\n",
    "    --model meta-llama/Llama-2-7b-hf \\\n",
    "    --wbits 2 \\\n",
    "    --group_size 64 \\\n",
    "    --calib_dataset redpajama \\\n",
    "    --train_size 128 \\\n",
    "    --val_size 32 \\\n",
    "    --epochs 1 \\\n",
    "    --layer_ordering sensitivity \\\n",
    "    --sensitivity_metric gradient \\\n",
    "    --sensitivity_samples 32 \\\n",
    "    --adaptive_lr_scaling \\\n",
    "    --output_dir ./test_adaptive_lr \\\n",
    "    --max_memory \"35GiB\" \\\n",
    "    --eval_ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Full Experiment Comparison\n",
    "\n",
    "Run a more comprehensive comparison with larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comparison script\n",
    "!python compare_methods.py --model meta-llama/Llama-2-7b-hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyze Results\n",
    "\n",
    "Let's analyze the performance improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load and display results\n",
    "try:\n",
    "    with open('./comparison_results/comparison_results.json', 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    # Create results dataframe\n",
    "    df_data = []\n",
    "    for result in results:\n",
    "        if result.get('success', False):\n",
    "            row = {\n",
    "                'Method': result.get('method', 'Unknown'),\n",
    "                'Duration (s)': result.get('duration', 0),\n",
    "                'WikiText2 PPL': result.get('wikitext2_ppl', 'N/A'),\n",
    "                'Avg Accuracy (%)': result.get('avg_accuracy', 'N/A')\n",
    "            }\n",
    "            df_data.append(row)\n",
    "    \n",
    "    if df_data:\n",
    "        df = pd.DataFrame(df_data)\n",
    "        print(\"=== LayerWise-QAT Results Comparison ===\")\n",
    "        print(df.to_string(index=False))\n",
    "        \n",
    "        # Calculate improvements\n",
    "        baseline = next((r for r in df_data if 'Baseline' in r['Method']), None)\n",
    "        if baseline:\n",
    "            print(\"\\n=== Improvements over Baseline ===\")\n",
    "            for row in df_data:\n",
    "                if 'Baseline' not in row['Method']:\n",
    "                    method = row['Method']\n",
    "                    if isinstance(row['Duration (s)'], (int, float)) and isinstance(baseline['Duration (s)'], (int, float)):\n",
    "                        speedup = baseline['Duration (s)'] / row['Duration (s)']\n",
    "                        print(f\"{method}: {speedup:.2f}x speedup\")\n",
    "    else:\n",
    "        print(\"No successful results found\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Results file not found. Run the comparison experiments first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}